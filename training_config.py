



NEPISODES               = 200           # Max training steps
NSTEPS                  = 300           # Max episode length
QVALUE_LEARNING_RATE    = 0.001         # Base learning rate for the Q-value Network
POLICY_LEARNING_RATE    = 0.0001        # Base learning rate for the policy network
DECAY_RATE              = 0.99          # Discount factor 
UPDATE_RATE             = 0.001           # Homotopy rate to update the networks
REPLAY_SIZE             = 10000          # Size of replay buffer
BATCH_SIZE              = 64            # Number of points to be fed in stochastic gradient
NH1                     = 400           # First hidden layer size     
NH2                     = 300           # Second hidden layer size
range_esp = 2.
time_step = 0.005



###PAPER PARAMETERS

# NEPISODES               = 200           # Max training steps
# NSTEPS                  = 200           # Max episode length
# QVALUE_LEARNING_RATE    = 0.001         # Base learning rate for the Q-value Network
# POLICY_LEARNING_RATE    = 0.0001        # Base learning rate for the policy network
# DECAY_RATE              = 0.99          # Discount factor 
# UPDATE_RATE             = 0.001           # Homotopy rate to update the networks
# REPLAY_SIZE             = 10000          # Size of replay buffer
# BATCH_SIZE              = 64            # Number of points to be fed in stochastic gradient
# NH1                     = 400           # First hidden layer size     
# NH2                     = 300           # Second hidden layer size
# range_esp = 2.